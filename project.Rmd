---
title: "BIO 260 Final Project - Yelp Restaurant Success Prediction"
output: html_document
---

# Data Wrangling

### Convert the JSON file into RData file
```{r}
install.packages("jsonlite")
library(jsonlite)
require(jsonlite)

business.file <- 'C:/Users/Phuong/Documents/R/Bio 260/yelp_dataset_challenge_academic_dataset/yelp_academic_dataset_business.json'

business <- stream_in(file(business.file))

save(business,file='C:/Users/Phuong/Documents/R/Bio 260/business.RData')

#rm(business)
```

```{r}
review.file <- 'C:/Users/Phuong/Documents/R/Bio 260/yelp_dataset_challenge_academic_dataset/yelp_academic_dataset_review.json'

review <- stream_in(file(review.file))

save(review,file='C:/Users/Phuong/Documents/R/Bio 260/review.RData')

#rm(review)
```

```{r}
user.file <- 'C:/Users/Phuong/Documents/R/Bio 260/yelp_dataset_challenge_academic_dataset/yelp_academic_dataset_user.json'

user <- stream_in(file(user.file))

save(user,file='C:/Users/Phuong/Documents/R/Bio 260/user.RData')

#rm(user)
```

Load our RData files.
```{r}
# set working directory
# Loading RData
library(dplyr)
library(tidyr)


y<-load("/Users/mingliu/Downloads/business.RData")
rm(y)

r <-load("/Users/mingliu/Downloads/review.RData")
rm(r)

u<-load("user.RData")
rm(u)
```

```{r}
# Data wrangling
lapply(business, class)
lapply(review,class)

```

Find all restaurants in QC and PA
```{r}
#table(business$state)

#Filter Restaurants in categories and states AZ,NV, NC,QC (states with more than 2000 restaurants)

#getting the index
business_restaurant_index <- which(grepl("Restaurants",business$categories) & business$state %in% c("QC","PA"))

#getting business id by index
business_restaurant_id <- business$business_id[business_restaurant_index]

review_restaurant_index <- which(review$business_id %in% business_restaurant_id)

review_restaurant_id <- review[review_restaurant_index,"review_id"]

# Filter review by review_id
review <- review[review$review_id %in% review_restaurant_id,]

#Filter business by business_id
business <-business[business$business_id %in% business_restaurant_id,] 

```

Specify some kind of foods and add them into dataset.
```{r,message=F,warning=F}
# Mexican, fast food, American, Asian, Europeans, Latin Americans

business$Mexican=NA
business$Fastfood=NA
business$American=NA
business$Asian=NA
business$European=NA

ff <- data.frame()
mex <- data.frame()
asia <- data.frame()
america <- data.frame()
european <- data.frame()

for (i in 1:length(business$categories)){
  ff<-rbind(ff,ifelse("Fast Food" %in% business$categories[[i]],1,0))
  mex <- rbind(mex, ifelse("Mexican" %in% business$categories[[i]],1,0))
  # asia <- rbind(asia,ifelse(c("Chinese","Japanese","Asian Fusion","Thai","Indian","Taiwanese","Vietnamese","Korean") %in% business$categories[[i]],1,0))
  asia <- rbind(asia,ifelse("Chinese" %in% business$categories[[i]]|"Japanese" %in% business$categories[[i]]|"Asian Fusion" %in% business$categories[[i]]|"Thai" %in% business$categories[[i]]|"Indian" %in% business$categories[[i]]|"Taiwanese" %in% business$categories[[i]]|"Vietnamese" %in% business$categories[[i]]|"Korean" %in% business$categories[[i]],1,0))
  america <- rbind(america,ifelse("American (New)" %in% business$categories[[i]]|"American (Traditional)" %in% business$categories[[i]],1,0))
  # european<-rbind(european,ifelse(c("Italian","French","Irish","Greek","Austrian","British","German") %in% business$categories[[i]],1,0))
   european <- rbind(european,ifelse("Italian" %in% business$categories[[i]]|"French" %in% business$categories[[i]]|"Irish" %in% business$categories[[i]]|"Greek" %in% business$categories[[i]]|"Austrian" %in% business$categories[[i]]|"British" %in% business$categories[[i]]|"German" %in% business$categories[[i]],1,0))
}

colnames(ff)[1]<- "Fastfood"
colnames(asia)[1]<-"Asia"
colnames(mex)[1] <- "Mexico"
colnames(america)[1] <- "America"
colnames(european)[1] <- "European"

business$Fastfood <- ff$Fastfood
business$Asian <-asia$Asia
business$Mexican <-mex$Mexico
business$American <- america$America
business$European <-european$European

rm(ff)
rm(asia)
rm(mex)
rm(america)
rm(european)
```

Count the number of features each restaurant has and sum them up. Add this new variable into the dataset.
```{r}
#Attributes: wifi, smoking, reservation, delivery, parking, credit card, happy hour, take out, drive thru
business$feature <- NA

#save all feature as a seperate data frame
tempA <- data.frame()

#reservation- false 11979, true 6042
tempA <- ifelse(business$attributes$`Takes Reservations`==TRUE,1,0) %>% as.data.frame()
colnames(tempA)[1]<- "reservation"

#delivery- false 14543, true 3364
tempA$delivery <- NA
tempA$delivery <- ifelse(business$attributes$Delivery==TRUE,1,0)

#credit card- false 397, true 18433
tempA$card <- NA
tempA$card <- ifelse(business$attributes$`Accepts Credit Cards`==TRUE,1,0)

#happy hour- false 238, true 1569
tempA$hh <- NA
tempA$hh <- ifelse(business$attributes$`Happy Hour`==TRUE,1,0) ##A lot NA, may remove

#take out- false 1385, true 16969
tempA$takeout <- NA
tempA$takeout <- ifelse(business$attributes$`Take-out`==TRUE,1,0)

#drive thru- false 1486, true 1387
tempA$drivethru <- NA
tempA$drivethru <- ifelse(business$attributes$`Drive-Thru`==TRUE,1,0) ##A lot NA, may remove

#Wifi- free 5224, no 8511, paid 118 - free+paid=1/no=0
tempA$wifi <- NA
tempA$wifi <- ifelse(business$attributes$`Wi-Fi`=="no",0,1) ##A lot NA

#smoking- no 636, outdoor 783, yes 239 - outdoor+yes=1/no=0
tempA$smoking <- NA
tempA$smoking <- ifelse(business$attributes$Smoking=="no",0,1) ##A lot NA

#parking- garage, street, validated, lot, valet - anyone returns true will be 1/otherwise 0
tempA$parking <- NA
tempA$parking <- ifelse(business$attributes$Parking$garage==TRUE|business$attributes$Parking$street==TRUE|business$attributes$Parking$validated==TRUE|business$attributes$Parking$lot==TRUE|business$attributes$Parking$valet==TRUE,1,0)

#Deal with NAs (replace NA to 0)
tempA <- tempA %>% replace_na(list(reservation=0, delivery=0, card=0, hh=0, takeout=0, drivethru=0, wifi=0, smoking=0, parking=0))

#Sum up to features
tempA <- mutate(tempA, feature = reservation + delivery + card + hh + takeout + drivethru + wifi + smoking + parking)

business$feature <- tempA$feature

rm(tempA)
```

Add some attributes from review dataset, including #funny, #useful, #cool
```{r, message=F,warning=F}
# select some columns of review and make it not a data.frame
tempB <- review%>%select(business_id,stars)
tempB <- tempB%>%mutate(vote_funny=review$votes$funny,
                        vote_useful=review$votes$useful,
                        vote_cool=review$votes$cool)
#group_by business 
r<-tempB%>%
  group_by(business_id)%>%
  summarise(votes_funny=sum(vote_funny),
            votes_useful=sum(vote_useful),
            votes_cool=sum(vote_cool))
rm(tempB)

# select columns in business
business_data <- business%>%
  select(business_id,full_address,city,review_count,
         state,stars,feature, Mexican, American, Fastfood, European, Asian)

#add other column of types data.frame to clean up the data.frame inside a data.frame
# business_data<-business_data%>%mutate(Mexican=business$Mexican,
#                                       American=business$American,
#                                       Fastfood=business$Fastfood,
#                                       European=business$European,
#                                       Asian=business$Asian)

#left_join the review columns with the business file 
business_data <- left_join(business_data,r,by="business_id")
#business_data <- business_data%>%mutate(avg_star=round(avg_star,digits=1))

#separate the zip code
business_data <- business_data %>% separate(full_address, c("address", "state_zc"), sep = ", ")
business_data <- business_data %>% separate(state_zc, c("st", "zip_code"), sep = "\\ ")
business_data <- business_data %>% select(-c(st,address,city))

```

Add some text analysis and finalize data wrangling part.
```{r}
library(tidytext)

review_text<-review %>%
    select(business_id, text, stars)%>%
    unnest_tokens(word, text)%>%
    filter(!word %in% stop_words$word)

nrc <- sentiments %>%
    filter(lexicon == "nrc") %>%
    select(word, sentiment)

review_sentiment <- review_text %>%
    inner_join(nrc) %>%
     count(business_id,sentiment)%>%
    spread(sentiment, n, fill = 0) %>%
    mutate(positivity = (positive - negative) / (positive + negative + 1))

# join with business_data
# use positivity
business_data <- review_sentiment%>%
  select(c(business_id,positivity))%>%
  left_join(business_data,by="business_id")
  
# state
business_data<- business_data%>%
  mutate(PA=ifelse(state=="PA",1,0))

business_data <- business_data%>%
  select(-c(zip_code))

# change the star columns in both review and business_data

business_data1<-business_data%>%
  mutate(stars=ifelse(stars >= 0 & stars<=1,1,
                ifelse(stars>1 & stars<=2,2,
                ifelse(stars>2 & stars<3,3,
                ifelse(stars>3 & stars<=4,4,5)))))

business_data1 <- subset(business_data1, select = -c(business_id) ) #with stars change

business_data <- subset(business_data, select = -c(business_id) ) # without stars change

```

# Plots

```{r}
# exploratory analysis
# graph, word cloud
library(caret)
library(wordcloud)
library(ggplot2)
library(easyGgplot2)

#word cloud by filtered 1-star yelp review/ 5-star yelp review (in review data)

common_1star <- review_text %>%
                  filter(stars==1) %>% count(word, sort = TRUE) %>% filter(n > 500)
pal1 <- brewer.pal(5, "RdPu")
pal1 <- pal1[-(1:2)]
wordcloud(common_1star$word, common_1star$n, colors = pal1, scale=c(12,.3))

common_5star <- review_text %>%
                  filter(stars==5) %>% count(word, sort = TRUE) %>% filter(n > 1000)
pal2 <- brewer.pal(5, "YlGn")
pal2 <- pal2[-(1:2)]
wordcloud(common_5star$word, common_5star$n, colors = pal2, scale=c(12,.3))

#review_count vs. stars/ positivity vs. stars
ggplot2.histogram(data=business_data1, xName='positivity',
        groupName='stars', legendPosition="top",
        alpha=0.5, addDensityCurve=TRUE, scale=density) + facet_wrap(~state)

ggplot2.barplot(data=business_data, xName='stars',yName='log10(review_count)', groupName = 'stars') + facet_wrap(~state)

#Max number of features vs. stars
max <- business_data %>% group_by(stars) %>% summarise(maxFeature = max(feature))
ggplot2.lineplot(data=max, xName='stars', yName='maxFeature', groupName = 'stars')
ggplot(max, aes(stars, maxFeature, color=stars)) + geom_point() + geom_line()


#http://colorbrewer2.org/ 
```


# Cross validation

```{r}
# cross validation

# create train set and test set with 80% in train and 20% in test
business_data1 <- business_data1 %>% select(-c(state))
business_data <- business_data %>% select(-c(state))

inTrain1 <- createDataPartition(y = business_data1$stars, p=0.8)
training1 <- slice(business_data1, inTrain$Resample1)
testing1 <- slice(business_data1, -inTrain$Resample1)

#run 10 cross validations leaving out 20% of the data
control <- trainControl(method='cv', number=10, p=.8) 

#with the business_data (no change in stars)
inTrain <- createDataPartition(y = business_data$stars, p=0.8)
training <- slice(business_data, inTrain$Resample1)
testing <- slice(business_data, -inTrain$Resample1)
```

# Fitting different models

### GLM (Logistic Regression)
```{r}
# fitting different models 
# classification 
# GLM (Logistic Regression)

fit1 <- glm(y~., data=mutate(training1,
                                   y=stars==1),family="binomial")
fit2 <- glm(y~., data=mutate(training1,
                                   y=stars==2),family="binomial")
fit3 <- glm(y~., data=mutate(training1,
                                   y=stars==3),family="binomial")
fit4 <- glm(y~., data=mutate(training1,
                                   y=stars==4),family="binomial")
fit5<- glm(y~., data=mutate(training1,
                                   y=stars==5),family="binomial")

f_hat1 <- predict(fit1, newdata = testing1, type = "response")
f_hat2 <- predict(fit2, newdata = testing1, type ="response")
f_hat3 <- predict(fit3, newdata = testing1, type = "response")
f_hat4 <- predict(fit4, newdata = testing1, type ="response")
f_hat5 <- predict(fit5, newdata = testing1, type = "response")

# warning messages? 

pred_glm <- apply(cbind(f_hat1, f_hat2, f_hat3,f_hat4,f_hat5),1,which.max)
```

### Linear model
```{r}
# fit business_data without change of stars
#fitting lm
library(broom)

#remove states in business_data
#data<-training%>%select(-c(state))

res_lm1 <- training%>%
  lm(stars ~ ., data = .)

summary(res_lm1)

#remove PA
res_lm2 <- training%>%
  lm(stars ~ positivity + review_count + feature + Mexican + American + Fastfood + European + Asian + votes_funny + votes_useful + votes_cool, data = .)

summary(res_lm2) 

#remove votes_usefull
res_lm3 <- training%>%
  lm(stars ~positivity + review_count + feature + Mexican + American + Fastfood + European+ Asian + votes_funny + votes_cool, data = .)

summary(res_lm3) #remove fast food

#remove European
res_lm4 <- training%>%
  lm(stars ~positivity + review_count + feature  + Mexican + American + Fastfood+ Asian + votes_funny + votes_cool, data = .)
summary(res_lm4) #remove feature

#remove Mexican
res_lm5 <- training%>%
  lm(stars ~positivity + review_count + feature + American + Fastfood+ Asian + votes_funny + votes_cool, data = .)
summary(res_lm5)

#RMSE = SD/(1-R^2)
rmse_lm <- 0.6164*sqrt(1-0.2795^2) #0.59

#backward selection, remove the high non-significant, and then do again until getting all significant
```

### KNN
```{r}
#KNN
res <- train(as.factor(stars) ~ .,
             data = training1,
             method = "knn",
             trControl = control,
             tuneLength = 1, # How fine a mesh to go on grid
             tuneGrid=data.frame(k=seq(1,20,2)),
             metric="Accuracy")

plot(res)

res$results %>% 
  ggplot(aes(k, Accuracy, ymin= Accuracy - AccuracySD, 
             ymax = Accuracy + AccuracySD)) +
  geom_point() + geom_errorbar()
res
# fit with k=19
fit <- knn3(stars~., data=training1, k=19)
f_hat <- predict(fit, newdata = testing1)
pred_knn_19 <- apply(f_hat,1,which.max)

#k changes everytime 

```

### SVM
```{r}
#SVM
#install.packages("e1071")
#Should we use the categorical stars variables or the original one???
library(e1071)
fit_svm <- svm(stars~.,data=training1) 
pred_svm <-predict(fit_svm,newdata=testing1)

# Random Forest
library(randomForest)
fit_rr<-randomForest(stars~.,data=training1)
pred_rr<-predict(fit_rr,newdata=testing1)
```

```{r}
RMSE <- function(true_ratings, predicted_ratings){
    sqrt(mean((true_ratings - predicted_ratings)^2))
}

rmse_glm <- RMSE(testing1$stars,pred_glm)
rmse_glm #0.300

rmse_knn_19<- RMSE(testing1$stars,pred_knn_19)
rmse_knn_19 #0.857

rmse_svm <- RMSE(testing1$stars,pred_svm)
rmse_svm #0.735

rmse_rr <- RMSE(testing1$stars,pred_rr)
rmse_rr #0.726
```

```{r}
library(knitr)
rmse_results <- data_frame(method = "Logistic Regression", RMSE = rmse_glm)

rmse_results <- bind_rows(rmse_results, data_frame(method = "Linear Regression", RMSE = rmse_lm))

rmse_results <- bind_rows(rmse_results,
                          data_frame(method="K Nearest Neighbors",  
                                     RMSE = rmse_knn_19 ))

rmse_results <- bind_rows(rmse_results,
                          data_frame(method="Support Vector Machine",  
                                     RMSE = rmse_svm ))

rmse_results <- bind_rows(rmse_results,
                          data_frame(method="Random Forest",  
                                     RMSE = rmse_rr ))


rmse_results%>%kable
```

